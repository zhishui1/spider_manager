## 爬虫逻辑修改计划

### 一、后端修改

#### 1.1 修改爬虫核心逻辑 (`backend/spiders/crawlers/nhsa/crawler.py`)

**新增Redis数据结构：**

* `spider:nhsa:phase`: 当前阶段 ('link\_collection' | 'detail\_crawling' | 'completed')

* `spider:nhsa:links_queue`: 待爬取的详情页链接队列 (List)

* `spider:nhsa:links_collected`: 已收集的链接总数

* `spider:nhsa:details_crawled`: 已爬取详情的数量

* `spider:nhsa:last_pagination_page`: 最后一页的页码（用于断点续爬）

* `spider:nhsa:crawled_urls`: 已爬取详情的URL集合（去重）

**重构爬虫流程：**

```python
def run(self):
    # 检查是否有未完成的翻页
    if self._has_incomplete_pagination():
        self._continue_pagination()  # 继续翻页收集链接
    
    # 检查是否有待爬取的详情链接
    if self._has_pending_links():
        self._crawl_details_from_queue()  # 从队列爬取详情
    
    # 两个阶段都完成则结束
    if self._is_all_complete():
        self.status_manager.set_status('completed', {})

def _has_incomplete_pagination(self) -> bool:
    """检查是否有未完成的翻页"""
    # 检查当前栏目和页码是否达到end_records

def _continue_pagination(self):
    """继续翻页收集链接"""
    # 翻页获取列表，将详情页URL存入links_queue

def _has_pending_links(self) -> bool:
    """检查是否有待爬取的详情链接"""
    return self.redis_client.llen('spider:nhsa:links_queue') > 0

def _crawl_details_from_queue(self):
    """从队列爬取详情页"""
    while self.redis_client.llen('spider:nhsa:links_queue') > 0:
        if self.should_stop:
            break
        link_data = self.redis_client.lpop('spider:nhsa:links_queue')
        self._process_detail_link(json.loads(link_data))
```

#### 1.2 修改适配器 (`backend/spiders/adapters.py`)

* `pause()` 方法不再需要（按钮已合并）

* 保留 `stop()` 方法，设置状态为 `stopped`

* 修改 `start()` 方法：启动时检查是否需要断点续爬

* 添加 `get_phase()` 方法返回当前爬取阶段

#### 1.3 修改后端API (`backend/spiders/views.py`)

* 移除 `pause` 和 `resume` action 处理

* 简化错误响应

#### 1.4 修改Redis管理器 (`backend/spiders/redis_manager.py`)

新增方法：

* `get_phase()`: 获取当前阶段

* `set_phase(phase)`: 设置当前阶段

* `push_to_links_queue(data)`: 推送链接到详情队列

* `pop_from_links_queue()`: 从详情队列取出

* `get_links_queue_size()`: 获取队列大小

* `get_crawled_count()`: 获取已爬取数量

* `increment_crawled_count()`: 增加已爬取数量

* `set_last_pagination_page(page)`: 记录翻页进度

* `get_last_pagination_page()`: 获取翻页进度

***

### 二、前端修改

#### 2.1 修改SpiderManager.tsx

**移除：**

* 暂停按钮

* 恢复按钮

* 暂停相关的disabled逻辑

**保留：**

* 启动按钮

* 停止按钮

* 刷新按钮

**新增状态显示：**

* 显示当前阶段（"收集链接中" / "爬取详情中" / "已完成"）

* 显示待爬取链接数量

***

### 三、实施步骤

1. **修改 redis\_manager.py** - 添加新的Redis操作方法
2. **修改 crawler.py** - 重构为两阶段爬取流程，支持断点续爬
3. **修改 adapters.py** - 适配新的爬虫控制逻辑
4. **修改 views.py** - 简化控制API
5. **修改 SpiderManager.tsx** - 更新UI，移除暂停/恢复按钮
6. **测试** - 验证断点续爬功能

***

### 四、预期效果

* 点击"启动"：如果上次停止时翻页未完成，继续翻页收集链接；如果翻页完成，则开始爬取详情页

* 点击"停止"：爬虫立即停止，保留进度

* 再次点击"启动"：从上次停止的位置继续（断点续爬）

